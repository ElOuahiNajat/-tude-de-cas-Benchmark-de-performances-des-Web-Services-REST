# Benchmark â€” Web Services REST (Jersey / Spring MVC / Spring Data REST)

**RÃ©sumÃ© :**  
Ce projet compare les performances de trois variantes REST Java :
- **A - Jersey** : implÃ©mentation JAX-RS (Grizzly).
- **C - Spring MVC** : Spring Boot avec contrÃ´leurs MVC classiques.
- **D - Spring Data REST** : exposition automatique des entitÃ©s via Spring Data REST.

Les tests de charge sont rÃ©alisÃ©s avec **Apache JMeter**. Les mÃ©triques applicatives (Micrometer) sont exportÃ©es vers **Prometheus** et affichÃ©es dans **Grafana**. Des collectors supplÃ©mentaires peuvent exporter vers **InfluxDB** si nÃ©cessaire. Le dÃ©ploiement et l'orchestration se font via **Docker / docker-compose**.

---

## FonctionnalitÃ©s principales
- 3 variantes REST implÃ©mentÃ©es et packagÃ©es.
- ScÃ©narios JMeter fournis (scripts `.jmx`) pour charges lÃ©gÃ¨res, mixtes et lourdes.
- Collecte de mÃ©triques via Micrometer â†’ Prometheus.
- Dashboards Grafana prÃ©configurÃ©s (CPU, mÃ©moire, latence, GC, threads, RPS).
- Docker Compose pour lancer rapidement lâ€™environnement complet.

---

## PrÃ©-requis
- Git
- Docker & Docker Compose (version rÃ©cente)
- Java 17+ (pour compiler les variantes si vous ne voulez pas utiliser les images fournies)
- Maven (si compilation locale)
- Apache JMeter (pour exÃ©cuter les tests localement)

---

## Installation & lancement (rapide)

```bash
# cloner le dÃ©pÃ´t
git clone https://github.com/ElOuahiNajat/-tude-de-cas-Benchmark-de-performances-des-Web-Services-REST.git
cd -tude-de-cas-Benchmark-de-performances-des-Web-Services-REST

# lancer l'environnement avec docker-compose (ex : compose dÃ©jÃ  fourni)
docker compose up --build

```
<img width="1033" height="565" alt="image" src="https://github.com/user-attachments/assets/d9784e36-ea4f-496d-8a31-2f9f26b22d45" />
## ğŸ§© 3. Structure du projet

Lâ€™architecture du projet est conÃ§ue de maniÃ¨re modulaire afin dâ€™isoler chaque implÃ©mentation REST tout en mutualisant les Ã©lÃ©ments communs (scripts, configuration et monitoring).  
Chaque module peut Ãªtre exÃ©cutÃ© et analysÃ© indÃ©pendamment pour une comparaison prÃ©cise des performances.

<img width="728" height="790" alt="image" src="https://github.com/user-attachments/assets/2e7b7200-0c95-409d-8dc0-59053460e063" />

## ğŸ³ 4. Conteneurs Docker

Lâ€™environnement de benchmark est entiÃ¨rement orchestrÃ© Ã  lâ€™aide de **Docker Compose**, garantissant une exÃ©cution reproductible et isolÃ©e des diffÃ©rents services.  
Chaque conteneur joue un rÃ´le spÃ©cifique dans la collecte, le stockage et la visualisation des performances.

ğŸ“ˆ Prometheus  â†’  Collecte les mÃ©triques exposÃ©es par les applications via Micrometer
ğŸ“Š Grafana     â†’  Visualise en temps rÃ©el les donnÃ©es issues de Prometheus et InfluxDB
ğŸ§® InfluxDB    â†’  Stocke les rÃ©sultats bruts des tests de charge JMeter
ğŸ§° API REST    â†’  Lâ€™une des trois variantes (Jersey, Spring MVC, Spring Data REST) testÃ©e
<img width="945" height="524" alt="image" src="https://github.com/user-attachments/assets/65589de0-b851-4f64-b20c-30529568dbc2" />
<img width="945" height="567" alt="image" src="https://github.com/user-attachments/assets/7f229f47-cbf7-45da-beaf-7d311393ba45" />
<img width="945" height="556" alt="image" src="https://github.com/user-attachments/assets/b3213867-5432-4504-8e87-9e52a6deddc0" />
<img width="945" height="129" alt="image" src="https://github.com/user-attachments/assets/f657f23f-f748-4902-9e51-36216cba6bdf" />

### Test des APIs
<img width="945" height="757" alt="image" src="https://github.com/user-attachments/assets/c9d6e323-5508-43f2-b4d0-53b143394ee4" />
<img width="945" height="727" alt="image" src="https://github.com/user-attachments/assets/d962e77a-1e70-439d-b44e-b305b531ed35" />

## ğŸ“‚ 5. Jeu de donnÃ©es initial â€” DataSeeder

Le benchmark sâ€™appuie sur un **jeu de donnÃ©es rÃ©aliste** gÃ©nÃ©rÃ© automatiquement par la classe `DataSeeder`.  
Lâ€™objectif est de simuler un environnement applicatif proche dâ€™une vraie application e-commerce avec un volume important dâ€™enregistrements et des relations complexes.

---


### âš™ï¸ GÃ©nÃ©ration du dataset

Le script `DataSeeder.java` insÃ¨re un **volume consÃ©quent de donnÃ©es** dans PostgreSQL pour reproduire un contexte rÃ©el :

| Ã‰lÃ©ment                     | DÃ©tail                                   |
|------------------------------|-----------------------------------------|
| Nombre de catÃ©gories         | 2 000 (Category)                        |
| Nombre dâ€™items par catÃ©gorie | 50 (Item)                                |
| Total dâ€™items gÃ©nÃ©rÃ©s        | 100 000                                  |
| Taille moyenne des descriptions | 5 120 caractÃ¨res (~5 Ko par item)    |
| Flush batch                  | 5 000 entitÃ©s (optimisation JPA / mÃ©moire) |

---

### ğŸ“œ Description du fonctionnement

Le seeder utilise **JPA (Jakarta Persistence)** via un `EntityManager` configurÃ© avec `FlushModeType.COMMIT` afin de trouver un Ã©quilibre entre **performance et cohÃ©rence**.

#### 1ï¸âƒ£ CrÃ©ation des catÃ©gories
- Boucle dâ€™insertion de **2 000 entitÃ©s `Category`**.
- Nettoyage rÃ©gulier du contexte de persistance avec `em.flush()` et `em.clear()` tous les **500 enregistrements** pour limiter la consommation mÃ©moire.

#### 2ï¸âƒ£ CrÃ©ation des items
- Boucle imbriquÃ©e gÃ©nÃ©rant **50 `Item` par catÃ©gorie**.
- RÃ©fÃ©rence directe de la catÃ©gorie via `em.getReference(Category.class, cid)` pour Ã©viter les rechargements inutiles.
- Flush automatique tous les **5 000 items** pour rÃ©duire la consommation mÃ©moire.

#### 3ï¸âƒ£ Attributs simulÃ©s
- Champs : `sku`, `name`, `price`, `stock`, `description`, `category`.
- Les descriptions sont gÃ©nÃ©rÃ©es via `generateLorem(5120)` pour simuler un **corps JSON dâ€™environ 5 Ko**, utile dans les scÃ©narios POST/PUT lourds (`HeavyBody`).

---

### ğŸ“Š Objectifs du dataset
- Reproduire des **volumes comparables Ã  un environnement e-commerce rÃ©el**.
- Ã‰valuer les performances sur :
  - Relations **N:1 / 1:N** (Category â†’ Item)
  - RequÃªtes **JOIN** et filtrÃ©es
  - Gestion des **corps JSON volumineux** dans les opÃ©rations dâ€™Ã©criture
  - Comportement de lâ€™application sous **charge intensive** (scÃ©narios JMeter)

---

ğŸ’¡ **Astuce :**  
Ce dataset permet de tester efficacement :
- La scalabilitÃ© des diffÃ©rentes implÃ©mentations REST
- Lâ€™impact des flush batch sur la mÃ©moire et le temps de traitement
- Les performances des endpoints CRUD avec de gros volumes de donnÃ©es
  
<img width="745" height="211" alt="image" src="https://github.com/user-attachments/assets/dc091eb8-ccba-4dd3-9dba-6e1003a7eef9" />
<img width="550" height="244" alt="image" src="https://github.com/user-attachments/assets/d45d5f54-8eb8-497b-8814-6ff5e531995d" />

## ğŸ“¡ 6. Configuration de Prometheus

La collecte des mÃ©triques applicatives pour le benchmark est entiÃ¨rement gÃ©rÃ©e par **Prometheus**.  
Le fichier `prometheus.yml` dÃ©finit les endpoints exposÃ©s par chaque service REST et les paramÃ¨tres de scraping.

---

### âš™ï¸ RÃ´le du fichier `prometheus.yml`
- SpÃ©cifie **les targets** Ã  surveiller (chaque variante REST : Jersey, Spring MVC, Spring Data REST).  
- Configure **la frÃ©quence de scraping** (intervalle entre chaque collecte de mÃ©triques).  
- DÃ©finit les labels et jobs pour organiser les donnÃ©es dans Grafana.
<img width="945" height="468" alt="image" src="https://github.com/user-attachments/assets/558aa7b2-ecf3-42ee-ac06-20595cb7a2ab" />
<img width="945" height="619" alt="image" src="https://github.com/user-attachments/assets/4705820f-34cf-403e-8194-dc254fcdcbfd" />

<img width="945" height="409" alt="image" src="https://github.com/user-attachments/assets/72c15041-c922-4927-ab3a-d93a936d04f0" />

<img width="902" height="498" alt="image" src="https://github.com/user-attachments/assets/57504479-345d-4a61-a0ce-e68a351cb484" />
<img width="895" height="502" alt="image" src="https://github.com/user-attachments/assets/30bab91a-ceca-4367-aa09-6e4ee231d15e" />

<img width="886" height="488" alt="image" src="https://github.com/user-attachments/assets/f0fc9a54-8440-402a-be95-7c54d26f58e9" />


## ğŸ§ª 7. ScÃ©narios de tests JMeter

Les benchmarks de performance ont Ã©tÃ© rÃ©alisÃ©s avec **Apache JMeter (v5.6.3)** afin de simuler diffÃ©rents types de charge sur les endpoints REST des trois implÃ©mentations :  
- JAX-RS (Jersey)  
- Spring MVC  
- Spring Data REST  

Trois types de scÃ©narios ont Ã©tÃ© dÃ©finis pour reprÃ©senter des profils dâ€™utilisation distincts : **lecture intensive** et **requÃªtes volumineuses**.

---

### ğŸ“˜ ScÃ©nario 1 â€” Lecture intensive (ReadHeavy)

Ce scÃ©nario vise Ã  Ã©valuer la capacitÃ© du serveur Ã  rÃ©pondre Ã  un **grand nombre de requÃªtes GET simultanÃ©es**, en simulant un trafic fortement orientÃ© lecture.

#### ğŸ”¹ ParamÃ¨tres du Thread Group
- **Nombre dâ€™utilisateurs (threads) :** 100  
- **Ramp-up period :** 60 secondes  
- **DurÃ©e totale du test :** 600 secondes  
- **Type de requÃªtes :** GET sur plusieurs endpoints  
- **RÃ©pÃ©tition :** Continue jusquâ€™Ã  la fin de la durÃ©e dÃ©finie  
- **Backend Listener :** Envoi des mÃ©triques vers InfluxDB

#### ğŸ”¹ Endpoints testÃ©s
- `GET /items?page=&size=`  
- `GET /items?categoryId=&page=&size=`  
- `GET /categories/{id}/items?page=&size=`  
- `GET /categories?page=&size=`

#### ğŸ”¹ Objectifs du test
- Mesurer **le throughput** (nombre de requÃªtes traitÃ©es par seconde)  
- Observer la **latence moyenne et maximale**  
- Suivre **lâ€™utilisation CPU et mÃ©moire** via Prometheus et Grafana  
- Identifier les **goulots dâ€™Ã©tranglement liÃ©s aux lectures simultanÃ©es**

<img width="945" height="512" alt="image" src="https://github.com/user-attachments/assets/46773384-c605-43b9-a19b-f33c3e9d9e7d" />

---

### ğŸ“˜ ScÃ©nario 2 â€” HeavyBody (RequÃªtes volumineuses)

Ce scÃ©nario simule des **POST/PUT avec des corps JSON lourds** (~5 Ko par item) afin de tester la performance du serveur lors dâ€™opÃ©rations dâ€™Ã©criture intensives.

#### ğŸ”¹ ParamÃ¨tres du Thread Group
- **Nombre dâ€™utilisateurs (threads) :** 50  
- **Ramp-up period :** 120 secondes  
- **DurÃ©e totale du test :** 600 secondes  
- **Type de requÃªtes :** POST / PUT sur les endpoints items  
- **Backend Listener :** InfluxDB pour collecte des mÃ©triques

#### ğŸ”¹ Objectifs du test
- Ã‰valuer la **gestion des gros payloads** par le serveur  
- Mesurer lâ€™impact sur **CPU, mÃ©moire et threads actifs**  
- VÃ©rifier la **stabilitÃ© de lâ€™application** sous Ã©criture lourde

---

ğŸ’¡ **Astuce :**  
Pour chaque scÃ©nario, les rÃ©sultats sont envoyÃ©s automatiquement Ã  **InfluxDB**, puis visualisÃ©s dans **Grafana** pour un suivi temps rÃ©el et une comparaison des trois implÃ©mentations REST.

<img width="945" height="494" alt="image" src="https://github.com/user-attachments/assets/a18fbd05-6da3-48a1-9f05-9e6874a42022" />


### ğŸ“˜ ScÃ©nario 3 â€” Join & Filter

Ce scÃ©nario simule des requÃªtes GET complexes combinant **jointures et filtres** sur les entitÃ©s `Category` et `Item`.  
Lâ€™objectif est de mesurer les performances du serveur lors de requÃªtes SQL plus lourdes et de vÃ©rifier la latence cÃ´tÃ© API.

#### ğŸ”¹ ParamÃ¨tres du Thread Group
- **Nombre dâ€™utilisateurs (threads) :** 60  
- **Ramp-up period :** 90 secondes  
- **DurÃ©e totale du test :** 600 secondes  
- **Type de requÃªtes :** GET avec paramÃ¨tres de filtrage et pagination  
- **Backend Listener :** Envoi des mÃ©triques vers InfluxDB

#### ğŸ”¹ Endpoints testÃ©s
- `GET /items?categoryId=&page=&size=&filter=price>100`  
- `GET /categories/{id}/items?page=&size=&filter=name~"Widget"`  
- `GET /items?page=&size=&filter=stock<50`  

#### ğŸ”¹ Objectifs du test
- Mesurer la **latence et le throughput** sur des requÃªtes filtrÃ©es et avec jointures  
- Observer lâ€™impact des **requÃªtes complexes sur CPU et mÃ©moire**  
- Comparer les performances des trois variantes REST lors dâ€™opÃ©rations de lecture filtrÃ©es  

ğŸ’¡ **Astuce :**  
- Les filtres simulÃ©s peuvent Ãªtre adaptÃ©s pour tester diffÃ©rents cas dâ€™usage (prix, stock, texte)  
- Les mÃ©triques collectÃ©es via InfluxDB et visualisÃ©es sur Grafana permettent de dÃ©tecter rapidement les goulots dâ€™Ã©tranglement liÃ©s aux JOIN et aux filtres complexes.

![WhatsApp Image 2025-11-11 Ã  22 40 16_99493623](https://github.com/user-attachments/assets/b4a1fd7b-e0ba-406c-9031-4e0a6d65dfcc)
### ğŸ“˜ ScÃ©nario 4 â€” Mixed (Lecture + Ã‰criture + Filtrage)

Ce scÃ©nario simule un **trafic mixte**, combinant des requÃªtes GET, POST et PUT afin de reproduire un profil utilisateur rÃ©aliste.  
Il permet de tester la **capacitÃ© globale du serveur** sous une charge variÃ©e.

#### ğŸ”¹ ParamÃ¨tres du Thread Group
- **Nombre dâ€™utilisateurs (threads) :** 80  
- **Ramp-up period :** 120 secondes  
- **DurÃ©e totale du test :** 600 secondes  
- **Type de requÃªtes :** GET (lecture), POST/PUT (Ã©criture), GET avec filtres (jointures)  
- **Backend Listener :** InfluxDB pour collecte des mÃ©triques en temps rÃ©el

#### ğŸ”¹ Endpoints testÃ©s
- `GET /items?page=&size=` â†’ lecture simple  
- `GET /items?categoryId=&page=&size=&filter=price>100` â†’ lecture filtrÃ©e  
- `POST /items` â†’ crÃ©ation dâ€™items avec corps JSON (~5 Ko)  
- `PUT /items/{id}` â†’ mise Ã  jour dâ€™items existants  
- `GET /categories/{id}/items?page=&size=&filter=stock<50` â†’ jointures + filtrage  

#### ğŸ”¹ Objectifs du test
- Mesurer la **latence moyenne et maximale** sous un mix de requÃªtes concurrentes  
- Suivre lâ€™impact des Ã©critures et des lectures filtrÃ©es sur **CPU, mÃ©moire et threads actifs**  
- Comparer les performances des trois implÃ©mentations REST sur un **profil utilisateur rÃ©aliste**  

ğŸ’¡ **Astuce :**  
- Ajuster le ratio GET/POST/PUT pour simuler diffÃ©rents profils de charge  
- Les mÃ©triques remontÃ©es dans Grafana permettent dâ€™identifier rapidement les **points faibles et goulets dâ€™Ã©tranglement**

![WhatsApp Image 2025-11-11 Ã  22 59 18_f5ffeda0](https://github.com/user-attachments/assets/59dcb90f-8976-448f-9230-7ba5a4621036)

####   Conclusion 

Ce projet compare les performances de trois implÃ©mentations REST Java : **JAX-RS (Jersey)**, **Spring MVC**, et **Spring Data REST**, Ã  lâ€™aide de **JMeter, Prometheus, Grafana, InfluxDB et Docker**.  
Lâ€™objectif est dâ€™Ã©valuer la capacitÃ© des serveurs Ã  gÃ©rer des charges lourdes et des volumes importants de donnÃ©es.

#### RÃ©alisÃ©es par : 

EL OUAHI Najat ET
HAILALA Yassmin
